{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7h7N_1X4lmI"
      },
      "source": [
        "## Lab Assignment: MNIST Classification Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0vR5I9h4s8V"
      },
      "source": [
        "Design your own MNIST Classification model (see video recording for explanation of MNIST dataset). You may choose your own hyperparameters, including:\n",
        "- Number of layers\n",
        "- Number of neurons in each layer\n",
        "- Learning rate\n",
        "- Number of training epochs\n",
        "- Optimizer\n",
        "\n",
        "Using a fully-connected network, you should be able to accomplish >90% accuracy on the test set. Please report your hyperparameter selections and accuracy in a summary at the end of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly85jvec6V6A"
      },
      "source": [
        "To load the MNIST dataset, we will use `torchvision`, which contains the datasets and has useful transformations. Start by defining the batch size you want for your training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p5dL4YeVorzV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lathe/miniconda3/envs/dl_lab/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "feGo1EKE4sRg"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "train_batch_size = 100 #Define train batch size\n",
        "test_batch_size  = 80 #Define test batch size (can be larger than train batch size)\n",
        "\n",
        "\n",
        "# Use the following code to load and normalize the dataset\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)), torchvision.transforms.Lambda(lambda x: torch.flatten(x))\n",
        "                             ])),\n",
        "  batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)), torchvision.transforms.Lambda(lambda x: torch.flatten(x))\n",
        "                             ])),\n",
        "  batch_size=test_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HrvoPg1f7Gxu"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "#Define your network:\n",
        "class Network(nn.Module):\n",
        "  def __init__(self): #Can provide additional inputs for initialization\n",
        "    #Define the network layer(s) and activation function(s)\n",
        "    super(Network, self).__init__()\n",
        "    self.layer1 = nn.Linear(784, 256)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.layer2 = nn.Linear(256, 64)\n",
        "    self.act2 = nn.ReLU()\n",
        "    self.layer3 = nn.Linear(64, 10)\n",
        "     \n",
        "\n",
        "  def forward(self, input):\n",
        "    #How does your model process the input?\n",
        "    x = self.act1(self.layer1(input))\n",
        "    x = self.act2(self.layer2(x))\n",
        "    output = self.layer3(x)\n",
        "  \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cpu')\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0F_DyktW8Bgw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0 \tTraining Loss: 0.268843 \tTraining Accuracy:  0.921317\n",
            "\n",
            "Epoch: 1 \tTraining Loss: 0.104336 \tTraining Accuracy:  0.968000\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 0.070362 \tTraining Accuracy:  0.977767\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 0.050124 \tTraining Accuracy:  0.984400\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 0.039948 \tTraining Accuracy:  0.987050\n"
          ]
        }
      ],
      "source": [
        "#Define your optimizer\n",
        "model = Network()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_accuracy = []\n",
        "train_loss = 0\n",
        "for epoch in range(epochs):\n",
        "  train_sample_counts = 0\n",
        "  epoch_corrects = 0 \n",
        "  train_loss = 0\n",
        "  for x_train, y_train in train_loader:\n",
        "    #Calculate training loss on model\n",
        "    x_train, y_train = x_train, y_train\n",
        "    y_pred = model(x_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    optimizer.zero_grad() # resest the gradients \n",
        "    loss.backward() # compute backpropagation\n",
        "    optimizer.step() # perform parameter update\n",
        "    # compute model metrics\n",
        "    predictions = torch.max(y_pred, 1)[1]\n",
        "    epoch_corrects += (predictions == y_train).sum()\n",
        "    train_sample_counts += len(y_train)\n",
        "    train_loss += loss.item() * x_train.size(0)\n",
        "    # print(epoch)\n",
        "    \n",
        "  epoch_accuracy = epoch_corrects/train_sample_counts\n",
        "  train_accuracy.append(epoch_accuracy)\n",
        "  train_loss_epoch = train_loss/train_sample_counts\n",
        "  print()\n",
        "  print(f'Epoch: {epoch} \\tTraining Loss: {train_loss_epoch:.6f} \\tTraining Accuracy:  {epoch_accuracy:.6f}')\n",
        "#Calculate loss on test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.975500\n"
          ]
        }
      ],
      "source": [
        "epoch_corrects = 0\n",
        "test_sample_counts = 0\n",
        "epoch_accuracy = 0\n",
        "for x_test, y_test in test_loader:    \n",
        "    #Calculate training loss on model\n",
        "    y_pred = model(x_test)\n",
        "    loss = criterion(y_pred, y_test)\n",
        "    predictions = torch.max(y_pred, 1)[1]\n",
        "    epoch_corrects += (predictions == y_test).sum()\n",
        "    test_sample_counts += len(y_test)\n",
        "\n",
        "    # print(epoch)\n",
        "epoch_accuracy = epoch_corrects/test_sample_counts\n",
        "print(f'Test Accuracy:  {epoch_accuracy:.6f}')\n",
        "# train_loss_epoch = test_loss/train_sample_counts\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqnEUuaAby8q"
      },
      "source": [
        "### Model Summary\n",
        "\n",
        "#### A. Which hyperparameters did you vary to achieve optimal performance? Please describe how you selected (random sampling? grid search? etc.) the hyperparameters you varied. \n",
        "I changed Adam optimizer's learning rate. Furthermore, I varied the fully connected neural netowrk's number of layers. I tested sigmoid and ReLU activation functions too.\n",
        "\n",
        "#### B. For the model that achieved the best performance, what values did you use for:\n",
        "1. Number of layers <br />\n",
        "I designed a 3-layers neural network. <br />\n",
        "2. Neurons in each layer <br />\n",
        "Hidden Layer 1: 256 <br />\n",
        "Higgen Layer 2: 64 <br />\n",
        "Output Layer: 10 <br />\n",
        "\n",
        "3. Activation function <br />\n",
        "I used ReLU activation function in all layers. <br />\n",
        "4. Learning Rate <br />\n",
        "I used Adam optimizer with learning rate = 1e-3 <br />\n",
        "5. Number of Training Epochs <br />\n",
        "I trained the network for 5 epochs <br />\n",
        "6. Other hyperparameters/layers (dropout, regularization, etc., if applicable) <br />\n",
        "I did not have any other hyperparameter. \n",
        "\n",
        "#### C. What was the accuracy on the test set for your best-performing network? <br />\n",
        "Best Test Accuracy = 0.9755 <br />\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR2MwC2mcIz4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac1wn7CKcMns"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EM6GQLv6j5uH"
      ],
      "name": "Lab 2- PyTorch Basics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
